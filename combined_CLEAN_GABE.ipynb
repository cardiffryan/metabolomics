{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196678\n"
     ]
    }
   ],
   "source": [
    "#Watershed on combined image region\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv.imread('/home/rcardiff/ryan/ryan/combined_img-4.png')\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "gray_inv = np.invert(gray)\n",
    "\n",
    "kernel1 = np.array([[-1,-1, -1], [0, 0, 0], [1, 1, 1]], np.uint8)\n",
    "opening = cv.morphologyEx(gray_inv,cv.MORPH_OPEN,kernel1, iterations = 3)\n",
    "#opening = dilation. turns pixel to 1 if a pixel under the kernel is 1, increasing size of object and \n",
    "#helping connect broken objects\n",
    "\n",
    "kernel2 = np.ones((3,3),np.uint8)\n",
    "grad = cv.morphologyEx(opening,cv.MORPH_GRADIENT, kernel2, iterations =1)\n",
    "\n",
    "\n",
    "# Marker labelling\n",
    "ret, markers = cv.connectedComponents(grad)\n",
    "# Add one to all labels so that sure background is not 0, but 1\n",
    "markers = markers+1\n",
    "markers = cv.watershed(img,markers)\n",
    "\n",
    "from skimage.measure import regionprops\n",
    "print(len(regionprops(markers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyteomics import mzxml, auxiliary\n",
    "import matplotlib.patches as mpatches\n",
    "import os\n",
    "from statistics import median\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import numpy as np\n",
    "\n",
    "feature_data = [x.bbox for x in regionprops(markers)]\n",
    "feature_list = [{} for x in regionprops(markers)]\n",
    "\n",
    "min_mzs = np.array([x[0] for x in feature_data])\n",
    "min_rts = np.array([x[1] for x in feature_data])\n",
    "max_mzs = np.array([x[2] for x in feature_data])\n",
    "max_rts = np.array([x[3] for x in feature_data])\n",
    "\n",
    "min_mzs = np.round(150.0 + (min_mzs * .001), decimals = 4)\n",
    "min_rts = np.round(min_rts * .02, decimals = 4)\n",
    "max_mzs = np.round(150.0 + (max_mzs * .001), decimals = 4)\n",
    "max_rts = np.round(max_rts * .02, decimals = 4)\n",
    "\n",
    "\n",
    "num_features = len(min_mzs)\n",
    "\n",
    "directory = \"/home/rcardiff/ryan/ryan/meyer_raw_data/C18_neg/CL/\"\n",
    "in_files = [os.path.join(directory, x) for x in os.listdir(directory) if x.endswith('.mzXML')]\n",
    "feature_list = [{} for r in regionprops(markers)]\n",
    "\n",
    "#2D lists with (number files) x (number features) dimensions\n",
    "running_feature_list_mz = [[[] for f in in_files] for r in regionprops(markers)]\n",
    "running_feature_list_rt = [[[] for f in in_files] for r in regionprops(markers)]\n",
    "running_feature_list_i = [[[] for f in in_files] for r in regionprops(markers)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "import sys\n",
    "from pandarallel import pandarallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions for scraping feature statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_file_df(fname):\n",
    "    f_data = mzxml.read(fname)\n",
    "    all_data =[(x['m/z array'], x['intensity array'], [float(x['retentionTime']) for y in x['m/z array']]) for x in f_data]\n",
    "    mzs = np.concatenate([x[0] for x in all_data])\n",
    "    intensities = np.concatenate([x[1] for x in all_data])\n",
    "    rts = np.concatenate([x[2] for x in all_data])\n",
    "    df_filedata = pd.DataFrame({'mz' : mzs, 'rt' : rts, 'intensity' : intensities})\n",
    "    return(df_filedata)\n",
    "\n",
    "def get_region_stats(feature, df_file):\n",
    "    df_keep = df_file.query(f\"mz>{feature['min_mz']} and mz<{feature['max_mz']} and rt>{feature['min_rt']} and rt<{feature['max_rt']}\")\n",
    "    if len(df_keep) == 0:\n",
    "        return([np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan])\n",
    "    mz_min, mz_med, mz_max = np.percentile(df_keep['mz'], [0, 50, 100])\n",
    "    rt_min, rt_med, rt_max = np.percentile(df_keep['rt'], [0, 50, 100])\n",
    "    int_mean = np.mean(df_keep['intensity'])\n",
    "    return([int_mean, mz_min, mz_max, mz_med, rt_min, rt_max, rt_med])\n",
    "\n",
    "@jit(nopython=True)\n",
    "def get_region_stats_vals(feature_vals, filedata_vals):\n",
    "    kept_data = filedata_vals.T[np.where((filedata_vals[0] > feature_vals[0]) & (filedata_vals[0] < feature_vals[1]) & (filedata_vals[1] > feature_vals[2]) & (filedata_vals[1] < feature_vals[3]))]\n",
    "    if len(kept_data) == 0:\n",
    "        return([np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan])\n",
    "    else:\n",
    "        mz_min, mz_med, mz_max = np.percentile(kept_data.T[0], [0, 50, 100])\n",
    "        rt_min, rt_med, rt_max = np.percentile(kept_data.T[1], [0, 50, 100])\n",
    "        int_mean = np.mean(kept_data.T[2])\n",
    "        return([int_mean, mz_min, mz_max, mz_med, rt_min, rt_max, rt_med])\n",
    "                            \n",
    "                            \n",
    "def add_df_col(fname, df_features, test = False):\n",
    "    if test:\n",
    "        df_features = pd.DataFrame(df_features.iloc[0 : 1000])\n",
    "    pandarallel.initialize(progress_bar=True, nb_workers=7)\n",
    "    feature_box_cols = ['min_mz', 'max_mz', 'min_rt', 'max_rt']\n",
    "    df_file = make_file_df(fname)\n",
    "    file_pref = os.path.basename(fname).strip('.mzXML')\n",
    "    out_col = df_features[feature_box_cols].parallel_apply(lambda x : get_region_stats_vals(x.values, df_file.values.T), axis = 1)\n",
    "    out_col = [x if not np.all(np.isnan(x)) else [] for x in out_col]\n",
    "    df_features[file_pref] = out_col\n",
    "    return(df_features)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframe based on features from regionprops and add a column for each .mzXML file with feature statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting feature stats for /home/rcardiff/ryan/ryan/meyer_raw_data/C18_neg/CL/CL8.mzXML\n",
      "INFO: Pandarallel will run on 7 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa51d791f3ee40fea379cf290dc81ac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=28097), Label(value='0 / 28097')))â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting feature stats for /home/rcardiff/ryan/ryan/meyer_raw_data/C18_neg/CL/CL3.mzXML\n",
      "INFO: Pandarallel will run on 7 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2be22b317652440498f7f8cd7cd1b598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=28097), Label(value='0 / 28097')))â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_features = pd.DataFrame({\n",
    "    'min_mz' : min_mzs,\n",
    "    'max_mz' : max_mzs,\n",
    "    'min_rt' : min_rts,\n",
    "    'max_rt' : max_rts\n",
    "})\n",
    "\n",
    "for i_fname, fname in enumerate(tqdm(in_files)):\n",
    "    print(f'Getting feature stats for {fname}')\n",
    "#     df_features = add_df_col(fname, df_features, test = True)\n",
    "    df_features = add_df_col(fname, df_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add feature ID column to dataframe and write to output tsv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file_name = \"df_features.tsv\"\n",
    "ndigits = len(str(len(df_features)))\n",
    "feature_ids = [f\"F{str(i).zfill(ndigits)}\" for i in range(len(df_features))]\n",
    "df_features.insert(0, 'feature_id', feature_ids)\n",
    "df_features.to_csv(out_file_name, sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
